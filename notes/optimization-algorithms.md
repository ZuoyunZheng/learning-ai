## Opimization Algorithms
Describes different optimization algorithms used in deep learning.

### Backgound
When we use linear regression we try to find a line that best fits the data,
by optimizing the intercept and the slope.
When we use logistic regression optimize a curve (squiggle).
There are more such optimization solutions like t-sne, pca, etc. But we can
use gradient decent to optimize all of the above.


### Stochoastic Gradient Descent
TODO:

### Stochastic Gradient Descent with Momentum
TODO:

### AdaGrad
TODO:

### RMSProp
TODO:

### Adam
TODO:
